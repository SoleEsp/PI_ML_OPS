{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORMACIONES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerias que vamos a necesitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Generar campo **`id`**: Cada id se compondrá de la primera letra del nombre de la plataforma, seguido del show_id ya presente en los datasets (ejemplo para títulos de Amazon = **`as123`**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos los archivos .cvs como dataframe con pandas.\n",
    "Se trabajaron con todos los csv individuales hasta que fuera necesario unirlos para que se pudiera ejecutar el codigo rapido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_prime = pd.read_csv('../dataset/amazon_prime_titles.csv',delimiter = ',',encoding = \"utf-8\")\n",
    "#df_amazon_prime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disney_plus = pd.read_csv('../dataset/disney_plus_titles.csv',delimiter= ',', encoding = \"utf-8\" )\n",
    "#df_disney_plus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hulu = pd.read_csv('../dataset/hulu_titles.csv',delimiter= ',', encoding = \"utf-8\" )\n",
    "#df_hulu.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netflix = pd.read_csv('../dataset/netflix_titles.csv',delimiter= ',', encoding = \"utf-8\" )\n",
    "#df_netflix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating1 = pd.read_csv('../dataset/rating/1.csv',delimiter = ',',encoding = \"utf-8\")\n",
    "#df_rating1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating2 = pd.read_csv('../dataset/rating/2.csv',delimiter = ',',encoding = \"utf-8\")\n",
    "#df_rating2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating3 = pd.read_csv('../dataset/rating/3.csv',delimiter = ',',encoding = \"utf-8\")\n",
    "#df_rating3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating4 = pd.read_csv('../dataset/rating/4.csv',delimiter = ',',encoding = \"utf-8\")\n",
    "#df_rating4.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating5 = pd.read_csv('../dataset/rating/5.csv',delimiter = ',',encoding = \"utf-8\")\n",
    "#df_rating5.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating6 = pd.read_csv('../dataset/rating/6.csv',delimiter = ',',encoding = \"utf-8\")\n",
    "#df_rating6.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating7 = pd.read_csv('../dataset/rating/7.csv',delimiter = ',',encoding = \"utf-8\")\n",
    "#df_rating7.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating8 = pd.read_csv('../dataset/rating/8.csv',delimiter = ',',encoding = \"utf-8\")\n",
    "#df_rating8.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el campo id de cada dataframe de plataforma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_prime = df_amazon_prime.assign(id='a' + df_amazon_prime['show_id'].astype(str))\n",
    "#df_amazon_prime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disney_plus = df_disney_plus.assign(id='d' + df_disney_plus['show_id'].astype(str))\n",
    "#df_disney_plus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hulu = df_hulu.assign(id='h' + df_hulu['show_id'].astype(str))\n",
    "#df_hulu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netflix = df_netflix.assign(id='n' + df_netflix['show_id'].astype(str))\n",
    "#df_netflix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Los valores nulos del campo rating deberán reemplazarse por el string “**`G`**” (corresponde al maturity rating: “general for all audiences”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_prime.fillna(value={'rating': 'G'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disney_plus.fillna(value={'rating': 'G'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hulu.fillna(value={'rating': 'G'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netflix.fillna(value={'rating': 'G'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificacion de nulos en la columna 'rating'\n",
    "print(df_amazon_prime['rating'].isnull().sum())\n",
    "print(df_disney_plus['rating'].isnull().sum())\n",
    "print(df_hulu['rating'].isnull().sum())\n",
    "print(df_netflix['rating'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- De haber fechas, deberán tener el formato **`AAAA-mm-dd`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se seleciona la columna del dataframe y con la funcion to_datetime cambiamos el formato\n",
    "# luego convertimos la columna a tipo DATATIME\n",
    "df_amazon_prime['date_added'] = pd.to_datetime(df_amazon_prime['date_added'].astype(str), format='%B %d, %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disney_plus['date_added'] = pd.to_datetime(df_disney_plus['date_added'].astype(str),format='%B %d, %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hulu['date_added'] = pd.to_datetime(df_hulu['date_added'].astype(str), format='%B %d, %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# antes de convertir al formato pedido se elimino el espacio en blanco de cada texto de la columna 'date_added' porque en este dataframe no dejaba realizar la conversion\n",
    "df_netflix['date_added'] = df_netflix['date_added'].str.lstrip() \n",
    "df_netflix['date_added'] = pd.to_datetime(df_netflix['date_added'].astype(str), format='%B %d, %Y')\n",
    "#df_netflix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating1['timestamp'] = pd.to_datetime(pd.to_datetime(df_rating1['timestamp'],unit='s').dt.strftime('%Y-%m-%d'))\n",
    "#df_rating1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating2['timestamp'] = pd.to_datetime(pd.to_datetime(df_rating2['timestamp'],unit='s').dt.strftime('%Y-%m-%d'))\n",
    "#df_rating2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating3['timestamp'] = pd.to_datetime(pd.to_datetime(df_rating3['timestamp'],unit='s').dt.strftime('%Y-%m-%d'))\n",
    "#df_rating3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating4['timestamp'] = pd.to_datetime(pd.to_datetime(df_rating4['timestamp'],unit='s').dt.strftime('%Y-%m-%d'))\n",
    "#df_rating4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating5['timestamp'] = pd.to_datetime(pd.to_datetime(df_rating5['timestamp'],unit='s').dt.strftime('%Y-%m-%d'))\n",
    "#df_rating5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating6['timestamp'] = pd.to_datetime(pd.to_datetime(df_rating6['timestamp'],unit='s').dt.strftime('%Y-%m-%d'))\n",
    "#df_rating6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating7['timestamp'] = pd.to_datetime(pd.to_datetime(df_rating7['timestamp'],unit='s').dt.strftime('%Y-%m-%d'))\n",
    "#df_rating7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating8['timestamp'] = pd.to_datetime(pd.to_datetime(df_rating8['timestamp'],unit='s').dt.strftime('%Y-%m-%d'))\n",
    "#df_rating8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificacion de cambio de formato\n",
    "df_amazon_prime.head()\n",
    "#df_disney_plus.head()\n",
    "#df_hulu.head()\n",
    "#df_netflix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Los campos de texto deberán estar en **minúsculas**, sin excepciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se recorrera todo el dataframe y donde haya un string se pasaran todas a minusculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_prime = df_amazon_prime.applymap(lambda x: x.lower() if type(x) == str else x)\n",
    "#df_amazon_prime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disney_plus = df_disney_plus.applymap(lambda x: x.lower() if type(x) == str else x)\n",
    "#df_disney_plus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hulu = df_hulu.applymap(lambda x: x.lower() if type(x) == str else x)\n",
    "#df_hulu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netflix = df_netflix.applymap(lambda x: x.lower() if type(x) == str else x)\n",
    "#df_netflix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- El campo ***duration*** debe convierte en dos campos: **`duration_int`** y **`duration_type`**. El primero será un integer y el segundo un string indicando la unidad de medición de duración: min (minutos) o season (temporadas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_prime['duration_int'] = df_amazon_prime['duration'].str.extract('(\\d+)').astype(int)\n",
    "df_amazon_prime['duration_type'] = df_amazon_prime['duration'].str.extract('([a-zA-Z]+)').replace('seasons', 'season')\n",
    "#df_amazon_prime.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disney_plus['duration_int'] = df_disney_plus['duration'].str.extract('(\\d+)').astype(int)\n",
    "df_disney_plus['duration_type'] = df_disney_plus['duration'].str.extract('([a-zA-Z]+)').replace('seasons', 'season')\n",
    "#df_disney_plus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hulu['duration_int'] = df_hulu['duration'].str.extract('(\\d+)').fillna(0).astype(int)\n",
    "df_hulu['duration_type'] = df_hulu['duration'].str.extract('([a-zA-Z]+)').replace('seasons', 'season')\n",
    "#df_hulu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netflix['duration_int'] = df_netflix['duration'].str.extract('(\\d+)').fillna(0).astype(int)\n",
    "df_netflix['duration_type'] = df_netflix['duration'].str.extract('([a-zA-Z]+)').replace('seasons', 'season')\n",
    "#df_netflix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para no tener datos repetidos se elimino la columna de **'duration'** de cada dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_prime.drop('duration', axis=1, inplace=True)\n",
    "df_disney_plus.drop('duration',axis=1, inplace=True)\n",
    "df_hulu.drop('duration',axis=1, inplace=True)\n",
    "df_netflix.drop('duration',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pasa a un csv con las trasformaciones realizadas.\n",
    "Se sigue trabajando con las plataformas individualmente para agilizar la carga y busqueda de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_prime.to_csv('../dataset_ETL/amazon_prime_ETL.csv',index=False)\n",
    "df_disney_plus.to_csv('../dataset_ETL/disney_plus_ETL.csv', index=False)\n",
    "df_hulu.to_csv('../dataset_ETL/hulu_ETL.csv', index=False)\n",
    "df_netflix.to_csv('../dataset_ETL/netflix_ETL.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DESARROLLO API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Funcion que calcula la Película con mayor duración con filtros opcionales de AÑO, PLATAFORMA Y TIPO DE DURACIÓN. (la función debe llamarse get_max_duration(year, platform, duration_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diccionario de nombres de archivo CSV para cada plataforma para aglizar la busqueda de valores\n",
    "dataframe = {\n",
    "        'Netflix': df_netflix,\n",
    "        'Amazon': df_amazon_prime,\n",
    "        'Disney': df_disney_plus,\n",
    "        'Hulu': df_hulu\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La plataforma \"disney\" no es válida. Las plataformas válidas son: Netflix, Disney, Amazon, Hulu.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_max_duration(year, platform, duration_type):\n",
    "\n",
    "    if platform not in dataframe:\n",
    "        return f'La plataforma \"{platform}\" no es válida. Las plataformas válidas son: Netflix, Disney, Amazon, Hulu.'\n",
    "    \n",
    "    #selecciona el csv segun la plataforma ingresada\n",
    "    selected_df = dataframe[platform]\n",
    "    \n",
    "    if duration_type not in ['min', 'season']:\n",
    "        return f'Por favor ingrese alguno de los siguientes valores correctos\\n duration_type: min o season'\n",
    "    \n",
    "    #se filtra el dataframe segun el año y tipo de duracion\n",
    "    selected_movies = selected_df.loc[(selected_df[\"release_year\"] == year) & (selected_df[\"duration_type\"] == duration_type)]\n",
    "\n",
    "    if selected_movies.empty:\n",
    "        return f\"No hay resultados para el año {year}. Intente con otro año.\"\n",
    "    \n",
    "    #se selecciona la pelicula, serie o tv_show con mayor duracion        \n",
    "    max_duration_movie = selected_movies.loc[selected_movies[\"duration_int\"].idxmax()]['title']\n",
    "\n",
    "    return f'Titulo: {max_duration_movie}'\n",
    "\n",
    "get_max_duration(2020,'disney','min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Cantidad de películas por plataforma con un puntaje mayor a XX en determinado año (la función debe llamarse get_score_count(platform, scored, year))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta funcion es necesario unir las plataformas en un csv y unir tambien los csv de ratings y crear en ese dataframe una columna **'scored'**. Luego hay que relacionar los 2 dataframe por medio del id y movieId\n",
    "Para esta función es necesario crear una columna 'scored' en el dataframe df_ratings y luego relacionar ese dataframe con lo csv de plataforma. Para esta ocasión se uniran los csv de las plataformas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms = pd.concat([df_amazon_prime,df_disney_plus,df_hulu,df_netflix])\n",
    "df_platforms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.concat([df_rating1, df_rating2, df_rating3, df_rating4,df_rating5, df_rating6,df_rating7, df_rating8])\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna **'scoreds'** tendra el promedio por pelicula\n",
    "La columna **'scored'** tendra el puntaje dado por el usuario. Tambien se cambian a minusculas los textos, se realiza aca para no hacer el cambio por cada csv de ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings['scoreds'] = df_ratings.groupby('movieId')['rating'].transform('mean')\n",
    "df_ratings['scoreds'] = df_ratings['scoreds'].round(1)\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = df_ratings.rename(columns={'rating': 'scored','userId': 'userid','movieId': 'movieid'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se relacionan las tablas mediante la columna **'id'** y **'movieid'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms = df_platforms.merge(df_ratings[['scored','userid','movieid', 'scoreds']], how='left', left_on='id', right_on='movieid')\n",
    "df_platforms.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos columnas que no seran necesarias.Antes de hacerlo se hizo una copia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms_copy = df_platforms.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms = df_platforms.drop(['show_id','movieid','director','cast','country','date_added','listed_in','description','rating','duration_int','duration_type'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cantidad de peliculas : 54852'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_score_count(platform, scored, year):\n",
    "    \n",
    "    #validacion de palabras correctas\n",
    "    if platform not in dataframe.keys():\n",
    "        return f'La plataforma \"{platform}\" no es válida. Las plataformas válidas son: Netflix, Disney, Amazon, Hulu.'\n",
    "    \n",
    "    # Obtener la inicial de la plataforma\n",
    "    platform_id = platform.lower()[0]\n",
    "    \n",
    "    df_filtered = df_platforms[df_platforms['type'] == 'movie']\n",
    "    # Filtrar el DataFrame por plataforma y año\n",
    "    df_filtered = df_platforms[(df_platforms['id'].str.startswith(platform_id)) & (df_platforms['release_year'] == year)]\n",
    "    \n",
    "    if df_filtered.empty:\n",
    "        return f\"No se encontraron resultados para el año {year}. Intente con otro año.\"\n",
    "    \n",
    "    #value_counts = df_filtered['scored'].value_counts()\n",
    "    \n",
    "    # Contar la cantidad de películas que tienen un puntaje mayor a scored\n",
    "    count = len(df_filtered[df_filtered['scoreds'] > scored])\n",
    "    \n",
    "    return f'Cantidad de peliculas : {count}'\n",
    "get_score_count('Disney', 3.0, 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un nuevo csv del dataframe df_platforms y de df_ratings. Se crea con to_parquet para que no sea tan pesado el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_parquet('../dataset_ETL/df_platforms_ETL.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.to_parquet('../dataset_ETL/ratings_ETL.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Cantidad de películas por plataforma con filtro de PLATAFORMA. (La función debe llamarse get_count_platform(platform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6131"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_count_platform(platform):\n",
    "    \n",
    "    if platform not in dataframe:\n",
    "        return print(f'La plataforma \"{platform}\" no es válida. Las plataformas válidas son: Netflix, Disney, Amazon, Hulu.')\n",
    "    \n",
    "    selected_df = dataframe[platform]\n",
    "    movie = selected_df[selected_df['type'] == 'movie']\n",
    "    \n",
    "    return movie.shape[0]\n",
    "get_count_platform('Netflix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Funcion que devuelve el Actor que más se repite según plataforma y año. (La función debe llamarse get_actor(platform, year))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ls siguiente funcion muestra el primer actor que mas se repide en la columna **'cast'**, y si hay mas de un actor devuelve el primero que aparece en la lista donde guarda los actores que mas se repiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Actor: anushka shetty, Cantidad de veces repetida: 7'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_actor(platform, year):\n",
    "    if platform not in dataframe:\n",
    "        return f'La plataforma \"{platform}\" no es válida. Las plataformas válidas son: Netflix, Disney, Amazon, Hulu.'\n",
    "    \n",
    "    selected_df = dataframe[platform]\n",
    "    \n",
    "    # Seleccionar solo los registros del año especificado\n",
    "    df_year = selected_df[selected_df['release_year'] == year]\n",
    "    \n",
    "    if df_year.empty:\n",
    "        return f\"No se encontraron resultados para el año {year}. Intente con otro año.\"\n",
    "    \n",
    "    # Dividir los nombres de los actores en una lista y contar las ocurrencias de cada uno\n",
    "    actor_counts = df_year['cast'].str.split(',').explode().str.strip().value_counts()\n",
    "    \n",
    "    # Devolver el nombre del actor más frecuente\n",
    "    most_frequent_actor = actor_counts.index[0]\n",
    "\n",
    "    return  f\"Actor: {most_frequent_actor}, Cantidad de veces repetida: {actor_counts[most_frequent_actor]}\"\n",
    "get_actor('Amazon',2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Sistema de recomendación`**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que toda la data es consumible por la API ya lista para consumir para los departamentos de Analytics y de Machine Learning, y nuestro EDA bien realizado entendiendo bien los datos a los que tenemos acceso, es hora de entrenar nuestro modelo de machine learning para armar un sistema de recomendación de películas para usuarios, donde dado un id de usuario y una película, nos diga si la recomienda o no para dicho usuario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"La película 'marvel studios' thor: ragnarok' no es recomendada.\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "def recommend_movie(user_id, movie_id):\n",
    "    # Seleccionar solo las columnas necesarias\n",
    "    ratings = df_platforms[['userid', 'title', 'scored']]\n",
    "\n",
    "    # Definir el rango de calificaciones\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "    # Cargar los datos\n",
    "    data = Dataset.load_from_df(ratings, reader)\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    algo = SVD()\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo.fit(trainset)\n",
    "\n",
    "    # Buscar el título de la película correspondiente\n",
    "    movie_title = df_platforms[df_platforms['id'] == movie_id]['title'].iloc[0]\n",
    "    \n",
    "    # Predecir la calificación del usuario para la película\n",
    "    prediction = algo.predict(user_id, movie_id, verbose=False)\n",
    "\n",
    "    # Obtener la predicción y devolver si la película es recomendada o no\n",
    "    if prediction.est >= 3.5:\n",
    "        return f\"La película '{movie_title}' es recomendada.\"\n",
    "    else:\n",
    "        return f\"La película '{movie_title}' no es recomendada.\"\n",
    "recommend_movie(119553,'ds686')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9d1f0f248df2f2363224f3e3a9963e167205723498f8c399a8b5aaef4a34a75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
